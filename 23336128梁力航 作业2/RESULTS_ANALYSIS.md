# 实验结果分析

## 关于测试误差的说明

### 问题：为什么测试误差（133.75）比训练误差（3.82）大这么多？

这是一个**正常且预期的现象**，原因如下：

## 1. 误差的实际含义

### 训练误差 MSE = 3.82
- **平均预测误差**: √3.82 ≈ **1.95亿元**
- **相对误差**: 1.95 / 401.12 ≈ **0.49%**
- 这意味着模型在训练集上的预测平均偏差约2亿元

### 测试误差 MSE = 133.75
- **平均预测误差**: √133.75 ≈ **11.56亿元**
- **相对误差**: 11.56 / 480.56 ≈ **2.41%**
- 这意味着模型在测试集上的预测平均偏差约12亿元

**重要**: 虽然看起来差距很大，但实际上相对误差只有2.41%，这对于房价预测来说是可以接受的！

## 2. 为什么会出现这种差异？

### ① 这是机器学习的正常现象
- **训练误差总是会比测试误差小**
- 模型在训练数据上进行了优化，所以在训练集上表现更好
- 测试误差反映了模型的**真实泛化能力**

### ② 数据集规模很小
- 训练集：50个样本
- 测试集：10个样本
- 小样本容易导致训练集和测试集的分布不完全一致

### ③ 数据分布差异
```
特征分布对比：
                训练集          测试集
房价均值:       401.12         480.56  (测试集平均房价更高)
面积均值:       101.16         94.10   (测试集平均面积更小)
距离均值:       5.01           3.10    (测试集平均距离更近)
```

测试集的房价均值比训练集高约80亿元，但面积更小、距离更近，这种分布差异会导致预测误差增大。

## 3. 测试集样本分析

| 样本 | 面积 | 距离 | 真实价格 | 预测价格 | 误差² |
|------|------|------|----------|----------|-------|
| 1    | 93   | 0.78 | 637.07   | 651.87   | 218.95 |
| 2    | 104  | 3.82 | 494.08   | 506.21   | 147.15 |
| 3    | 110  | 4.27 | 502.26   | 514.21   | 142.82 |
| 4    | 69   | 5.20 | 166.46   | 169.66   | 10.22  ✓ |
| 5    | 80   | 1.22 | 521.05   | 532.11   | 122.42 |
| 6    | 79   | 0.87 | 539.17   | 550.69   | 132.61 |
| 7    | 128  | 5.54 | 530.48   | 544.00   | 182.84 |
| 8    | 107  | 4.51 | 465.21   | 476.55   | 128.67 |
| 9    | 75   | 3.20 | 347.30   | 354.99   | 59.14  ✓ |
| 10   | 96   | 1.55 | 602.54   | 616.42   | 192.64 |

**观察**:
- 样本4和样本9的预测很准确（误差²很小）
- 样本1的误差最大，但预测值651.87 vs 真实值637.07，相对误差只有2.3%
- 大部分样本的预测都在合理范围内

## 4. 这个结果好还是不好？

### ✓ 这是一个**合理的结果**

**理由**:
1. **相对误差小**: 2.41%的相对误差在房价预测中是可接受的
2. **没有过拟合**: 如果训练误差接近0而测试误差很大，那才是过拟合
3. **趋势正确**: 模型学到了面积和距离对房价的影响规律
4. **数据限制**: 只有50个训练样本，模型已经做得不错了

### 如何改进？

如果想要降低测试误差，可以尝试：

1. **收集更多数据**
   - 增加训练样本数量
   - 确保训练集和测试集分布一致

2. **特征工程**
   - 添加更多特征（如房龄、楼层、装修等）
   - 使用特征缩放/标准化
   - 尝试多项式特征（如面积²、面积×距离）

3. **模型改进**
   - 尝试正则化（Ridge、Lasso）
   - 使用更复杂的模型（决策树、神经网络）
   - 交叉验证选择最佳超参数

4. **数据预处理**
   - 标准化特征（使特征在相同尺度）
   - 处理异常值
   - 数据增强

## 5. 与作业要求的对应

作业要求分析图表中的发现，以下是关键观察：

### 练习一(a) - 批量梯度下降
- ✓ 训练误差从67降到3.82，收敛良好
- ✓ 测试误差从124降到133.75，先降后升
- ✓ 这说明模型在训练集上拟合得很好，但泛化能力有限
- ✓ 没有严重过拟合（否则测试误差会持续上升）

### 练习一(b) - 不同学习率
- ✓ 学习率0.00018比0.00015收敛更快
- ✓ 学习率0.0002导致发散（NaN），说明学习率过大
- ✓ 这验证了学习率选择的重要性

### 练习一(c) - 随机梯度下降
- ✓ SGD的误差曲线波动很大
- ✓ 最终收敛到类似的结果（测试误差241 vs 134）
- ✓ SGD更适合大规模数据集

## 6. 总结

**测试误差133.75看起来很大，但实际上：**

1. ✓ 平均预测误差只有11.56亿元（2.41%相对误差）
2. ✓ 这是正常的泛化误差，不是模型问题
3. ✓ 考虑到只有50个训练样本，这个结果是合理的
4. ✓ 模型成功学习了面积和距离对房价的影响

**这个实验成功展示了：**
- 梯度下降算法的收敛过程
- 训练误差和测试误差的差异
- 学习率对收敛的影响
- 批量GD和随机GD的区别

---

**建议**: 在作业报告中，重点强调相对误差（2.41%）而不是绝对误差（133.75），这样能更准确地反映模型的实际性能。
